{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply kernelized ridge regression to the automobile mpg dataset. The training data and test data\n",
    "are provided in auto mpg train.csv and auto mpg test.csv, respectively. The first column is the\n",
    "mpg data while the other 7 columns are the features:\n",
    "1. mpg: continuous\n",
    "2. cylinders: multi-valued discrete\n",
    "3. displacement: continuous\n",
    "4. horsepower: continuous\n",
    "5. weight: continuous\n",
    "6. acceleration: continuous\n",
    "7. model year: multi-valued discrete\n",
    "8. origin: multi-valued discrete\n",
    "\n",
    "We have normalized the feature data to the range [0,1]. Please apply the kernelized ridge regression\n",
    "to this dataset (use mpg as the target, the other 7 columns as features). Report the RMSE (Root\n",
    "Mean Square Error) of the models on the test data. Try (set lamda = 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need to normlize the features between 0 and 1, this is the function to do so\n",
    "\n",
    "def NormalizeData(data):\n",
    "    return (data - np.min(data)) / (np.max(data) - np.min(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 7) (299,) (97, 7) (97,)\n"
     ]
    }
   ],
   "source": [
    "#read in train and test data\n",
    "\n",
    "te = pd.read_csv('auto_mpg_test.csv', sep = ' ')\n",
    "\n",
    "tr = pd.read_csv('auto_mpg_train.csv', sep = ' ')\n",
    "\n",
    "\n",
    "tes = pd.DataFrame(te).to_numpy()\n",
    "\n",
    "tra = pd.DataFrame(tr).to_numpy()\n",
    "\n",
    "#split features (x) and labels (mpg, y)\n",
    "\n",
    "x_tra = tra[:, 1:8]\n",
    "\n",
    "y_train = tra[:, 0]\n",
    "\n",
    "x_tes = tes[:, 1:8]\n",
    "\n",
    "y_test = tes[:, 0]\n",
    "\n",
    "#normalize features (x_test and x_train)\n",
    "\n",
    "x_test = NormalizeData(x_tes)\n",
    "\n",
    "x_train = NormalizeData(x_tra)\n",
    "\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we can you sklearn (THANK YOU!!!!!), we can use the built in sklearn.kernel_ridge.KernelRidge function. \n",
    "\n",
    "Thankfully, we can call the KernelRidge function with the kernel='rbf' instead of it's default linear kernel. \n",
    "\n",
    "The rbf kernel uses the gaussian distribution asked in the question. See this link for documentation proof:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.rbf_kernel.html\n",
    "The default rbf kernel sets sigma = 1, as asked in the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error for Gaussian Kernel:  3.2102263635542707\n"
     ]
    }
   ],
   "source": [
    "#Kernel Ridge Regression from sklearn using rbf (gaussian) kernel\n",
    "skKRR = KernelRidge(alpha=1.0, kernel='rbf', gamma = 1/2)\n",
    "\n",
    "#fit kernel to train data\n",
    "skKRR.fit(x_train, y_train)\n",
    "\n",
    "#predict test data\n",
    "skKRR_y_pred = skKRR.predict(x_test)\n",
    "\n",
    "#report root mean squared error \n",
    "rmse = np.sqrt(mean_squared_error(y_true=y_test,y_pred=skKRR_y_pred))\n",
    "print(\"Root Mean Squared Error for Gaussian Kernel: \",rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of curiosity (and because this is a short question due to sklearn), I want to try to see the difference between linear and rbf kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error for Liner Kernel:  5.207784717373817\n"
     ]
    }
   ],
   "source": [
    "#Kernel Ridge Regression from sklearn using liner kernel\n",
    "skKRR_lin = KernelRidge(alpha=1.0)\n",
    "\n",
    "#fit kernel to train data\n",
    "skKRR_lin.fit(x_train, y_train)\n",
    "\n",
    "#predict test data\n",
    "skKRR_y_pred_lin = skKRR_lin.predict(x_test)\n",
    "\n",
    "#report root mean squared error \n",
    "rmse_lin = np.sqrt(mean_squared_error(y_true=y_test,y_pred=skKRR_y_pred_lin))\n",
    "print(\"Root Mean Squared Error for Liner Kernel: \",rmse_lin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the Gaussian Kernel is superior!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
