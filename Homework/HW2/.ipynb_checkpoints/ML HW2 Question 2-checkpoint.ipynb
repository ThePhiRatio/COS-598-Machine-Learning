{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Spam Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem you will apply the naive Bayes classifer to the problem of spam detection, using a benchmark database assembled by researchers at Hewlett-Packard. Download the file spambase.data from Brightspace under HW2, and issue the following commands to load the data. In Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "z = np.genfromtxt('spambase.data', dtype=float, delimiter=',')\n",
    "np.random.seed(0) #Seed the random number generator\n",
    "rp = np.random.permutation(z.shape[0]) #random permutation of indices\n",
    "z = z[rp,:] #shuffle the rows of z\n",
    "x = z[:,:-1]\n",
    "y = z[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here X is n x d, where n = 4601 and d = 57. The different features correspond to different properties of an email, such as the frequency with which certain characters appear. y is a vector of labels indicating spam or not spam. For a detailed description of the dataset, visit the UCI Machine Learning Repository, or Google 'spambase'.\n",
    "\n",
    "To evaluate the method, treat the first 2000 examples as training data, and the rest as test data. Fit the naive Bayes model using the training data (i.e., estimate the class-conditional marginals), and compute the misclassification rate (i.e., the test error) on the test data. The code above randomly permutes the data, so that the proportion of each class is about the same in both training and test data.\n",
    "\n",
    "Note: On the spam detection problem, please note that you will get a different test error depending on how you quantize values that are equal to the median. It makes a difference whether you quantize values equal to the median to 1 or 2. You should quantize all medians the same way - I'm not suggesting that you try all 2d combinations. So just make sure you try both options, and report the one that works better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantize each variable to one of two values, say 1 and 2, so that values below the median map\n",
    "to 1, and those above map to 2.\n",
    "\n",
    "To get the median in Python, use np.median(a,axis=0).\n",
    "\n",
    "Report the test error. As a sanity check, what would be the test error if you always predicted the same class, namely, the majority class from the training data?\n",
    "\n",
    "Note: In class you may learn the Laplace Smoothing technique but in this problem you don't need to\n",
    "implement this technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4601, 57) (4601,)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "med = np.median(x, axis=0)\n",
    "for i in range(len(x)):\n",
    "    for j in range(len(x[i])):\n",
    "        if x[i][j] <= med[j]:\n",
    "            x[i][j] = 0\n",
    "        else:\n",
    "            x[i][j] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 57) (2601, 57) (2000,) (2601,)\n"
     ]
    }
   ],
   "source": [
    "#split into train and test data \n",
    "train_size = 2000\n",
    "x_train = x[:train_size, :]\n",
    "x_test = x[train_size:, :]\n",
    "y_train = y[:train_size]\n",
    "y_test = y[train_size:]\n",
    "\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 57 2\n"
     ]
    }
   ],
   "source": [
    "num_examples, num_features = x_train.shape\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "print(num_examples, num_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1193, 807]\n"
     ]
    }
   ],
   "source": [
    "#num of documents in a class divided by the total number of documents is priors\n",
    "priors = [0,0]\n",
    "for i in y_train:\n",
    "    if i==0:\n",
    "        priors[0] += 1\n",
    "    else:\n",
    "        priors[1] += 1\n",
    "        \n",
    "print(priors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate n_k for all classes\n",
    "n_kt = []\n",
    "for cls in range (num_classes):\n",
    "    sum = 0\n",
    "    for i in range (len(y_train)):\n",
    "        if y_train[i] == cls:\n",
    "            sum += 1\n",
    "    n_kt.append(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate feature amounts for n_kl\n",
    "features = np.zeros((num_examples,num_features,num_classes))\n",
    "for cls in range (num_classes):\n",
    "    for feat in range(num_features):\n",
    "        for i in {0,1}:\n",
    "            sum = 0\n",
    "            for r in range(len(y_train)):\n",
    "                if y_train[r] == cls and i == x_train[r][feat]:\n",
    "                    sum += 1\n",
    "            features[cls][feat][i] = sum\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(r):\n",
    "    answer = []\n",
    "    for cls in range (num_classes):\n",
    "        p = 1\n",
    "        \n",
    "        for feat in range(num_features):\n",
    "            \n",
    "            #calculate n_kl\n",
    "            n_kl = features[cls][feat][int(x_test[r][feat])]\n",
    "            \n",
    "            #input n_k from n_kt\n",
    "            n_k = n_kt[cls]\n",
    "            \n",
    "            p *= n_kl/float(n_k)\n",
    "            \n",
    "        answer.append(priors[cls]*p)\n",
    "    return np.argmax(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_percent(test_data, prediction):\n",
    "    sum = 0\n",
    "    for i in range(len(test_data)):\n",
    "        if test_data[i] == prediction[i]:\n",
    "            sum += 1\n",
    "    return ((sum/len(y_test))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.38869665513263%\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "for i in range (len(y_test)):\n",
    "    predictions.append(predict(i))\n",
    "\n",
    "print(str(accuracy_percent(y_test, predictions))+\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have found that if I allow quantized values that are equal to the median go into class 1 (aka 2) then I get a percent accuracy of 75.74%.\n",
    "\n",
    "If I allow quantized values that are equal to the median to be go into class 0 (aka 1) then I get a percent accuracy of 89.39%.\n",
    "\n",
    "Therefore, experimentally it seems that the better accuracy favors the <= case into class 0.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
